---
title: vLLM
icon: rocket
---

# vLLM

vLLM æ˜¯é«˜æ€§èƒ½ LLM æ¨ç†å¼•æ“ï¼Œä¸“ä¸ºç”Ÿäº§ç¯å¢ƒè®¾è®¡ã€‚

## ğŸ“Œ å·¥å…·æ¦‚è¿°

vLLM ç”± UC Berkeley å¼€å‘ï¼Œä»¥å…¶åˆ›æ–°çš„ PagedAttention æŠ€æœ¯è‘—ç§°ã€‚

### æ ¸å¿ƒç‰¹ç‚¹
- **é«˜ååé‡**ï¼šPagedAttention æŠ€æœ¯
- **ä½å»¶è¿Ÿ**ï¼šæŒç»­æ‰¹å¤„ç†
- **æ˜“éƒ¨ç½²**ï¼šOpenAI å…¼å®¹ API
- **å¤šæ¨¡å‹**ï¼šæ”¯æŒä¸»æµ LLM

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
pip install vllm
```

### ç¦»çº¿æ¨ç†

```python
from vllm import LLM, SamplingParams

# åŠ è½½æ¨¡å‹
llm = LLM(model="meta-llama/Llama-2-7b-chat-hf")

# é…ç½®å‚æ•°
sampling_params = SamplingParams(
    temperature=0.7,
    top_p=0.95,
    max_tokens=256
)

# ç”Ÿæˆ
prompts = ["ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±", "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"]
outputs = llm.generate(prompts, sampling_params)

for output in outputs:
    print(output.outputs[0].text)
```

### å¯åŠ¨ API æœåŠ¡

```bash
python -m vllm.entrypoints.openai.api_server \
    --model meta-llama/Llama-2-7b-chat-hf \
    --host 0.0.0.0 \
    --port 8000
```

### è°ƒç”¨ API

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="token"
)

response = client.chat.completions.create(
    model="meta-llama/Llama-2-7b-chat-hf",
    messages=[{"role": "user", "content": "ä½ å¥½"}]
)
```

## âš¡ æ ¸å¿ƒæŠ€æœ¯

### PagedAttention

å°† KV Cache åˆ†é¡µç®¡ç†ï¼Œå¤§å¹…å‡å°‘å†…å­˜æµªè´¹ã€‚

```
ä¼ ç»Ÿæ–¹å¼ï¼šè¿ç»­åˆ†é… â†’ å†…å­˜ç¢ç‰‡å¤š
PagedAttentionï¼šåˆ†é¡µç®¡ç† â†’ å†…å­˜åˆ©ç”¨ç‡é«˜
```

### Continuous Batching

åŠ¨æ€æ‰¹å¤„ç†ï¼Œæ–°è¯·æ±‚æ— éœ€ç­‰å¾…ã€‚

## ğŸ”§ å¸¸ç”¨é…ç½®

```bash
python -m vllm.entrypoints.openai.api_server \
    --model meta-llama/Llama-2-7b-chat-hf \
    --tensor-parallel-size 2 \           # å¤š GPU
    --gpu-memory-utilization 0.9 \       # GPU å†…å­˜ä½¿ç”¨ç‡
    --max-model-len 4096 \               # æœ€å¤§ä¸Šä¸‹æ–‡
    --quantization awq                    # é‡åŒ–
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| å¼•æ“ | ååé‡ | å»¶è¿Ÿ |
|------|--------|------|
| HuggingFace | 1x | é«˜ |
| TGI | 3-4x | ä¸­ |
| vLLM | 10-24x | ä½ |

## ğŸ“š å»¶ä¼¸é˜…è¯»

- [vLLM å®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/)
- [æ¨¡å‹éƒ¨ç½²](/llm/deployment)
- [æ¨¡å‹é‡åŒ–](/llm/quantization)
