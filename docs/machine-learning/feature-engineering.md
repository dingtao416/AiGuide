---
title: ç‰¹å¾å·¥ç¨‹
icon: filter
---

# ç‰¹å¾å·¥ç¨‹

ç‰¹å¾å·¥ç¨‹æ˜¯æœºå™¨å­¦ä¹ ä¸­å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ›´å¥½è¡¨ç¤ºçš„è¿‡ç¨‹ï¼Œå¥½çš„ç‰¹å¾å¯ä»¥æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ¯ ä»€ä¹ˆæ˜¯ç‰¹å¾å·¥ç¨‹

ç‰¹å¾å·¥ç¨‹ï¼ˆFeature Engineeringï¼‰æ˜¯æŒ‡ä½¿ç”¨é¢†åŸŸçŸ¥è¯†ä»åŸå§‹æ•°æ®ä¸­æå–ã€é€‰æ‹©å’Œè½¬æ¢ç‰¹å¾çš„è¿‡ç¨‹ï¼Œä»¥æé«˜æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ã€‚

> "æ•°æ®å’Œç‰¹å¾å†³å®šäº†æœºå™¨å­¦ä¹ çš„ä¸Šé™ï¼Œè€Œæ¨¡å‹å’Œç®—æ³•åªæ˜¯é€¼è¿‘è¿™ä¸ªä¸Šé™ã€‚" â€” æœºå™¨å­¦ä¹ ç•Œåè¨€

## ğŸ“Š ç‰¹å¾å·¥ç¨‹æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ç‰¹å¾å·¥ç¨‹æµç¨‹                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  åŸå§‹æ•°æ® â†’ æ•°æ®æ¸…æ´— â†’ ç‰¹å¾æå– â†’ ç‰¹å¾é€‰æ‹© â†’ ç‰¹å¾è½¬æ¢ â†’ å»ºæ¨¡    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ å¸¸ç”¨æŠ€æœ¯

### 1. æ•°å€¼ç‰¹å¾å¤„ç†

#### æ ‡å‡†åŒ– (Standardization)
å°†æ•°æ®è½¬æ¢ä¸ºå‡å€¼ä¸º 0ã€æ ‡å‡†å·®ä¸º 1 çš„åˆ†å¸ƒã€‚

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

#### å½’ä¸€åŒ– (Normalization)
å°†æ•°æ®ç¼©æ”¾åˆ° [0, 1] èŒƒå›´ã€‚

```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_normalized = scaler.fit_transform(X)
```

#### å¯¹æ•°å˜æ¢
å¤„ç†åæ€åˆ†å¸ƒçš„æ•°æ®ã€‚

```python
import numpy as np
X_log = np.log1p(X)  # log(1+x)ï¼Œé¿å… log(0)
```

### 2. ç±»åˆ«ç‰¹å¾å¤„ç†

#### One-Hot ç¼–ç 
å°†ç±»åˆ«å˜é‡è½¬æ¢ä¸ºäºŒè¿›åˆ¶å‘é‡ã€‚

```python
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(sparse=False)
X_encoded = encoder.fit_transform(X_categorical)
```

#### Label ç¼–ç 
å°†ç±»åˆ«æ˜ å°„ä¸ºæ•´æ•°ã€‚

```python
from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)
```

#### Target ç¼–ç 
ç”¨ç›®æ ‡å˜é‡çš„ç»Ÿè®¡é‡æ›¿æ¢ç±»åˆ«å€¼ã€‚

```python
# è®¡ç®—æ¯ä¸ªç±»åˆ«çš„ç›®æ ‡å‡å€¼
target_means = df.groupby('category')['target'].mean()
df['category_encoded'] = df['category'].map(target_means)
```

### 3. ç¼ºå¤±å€¼å¤„ç†

```python
from sklearn.impute import SimpleImputer

# æ•°å€¼ç‰¹å¾ç”¨å‡å€¼å¡«å……
num_imputer = SimpleImputer(strategy='mean')

# ç±»åˆ«ç‰¹å¾ç”¨ä¼—æ•°å¡«å……
cat_imputer = SimpleImputer(strategy='most_frequent')
```

### 4. ç‰¹å¾ç”Ÿæˆ

#### å¤šé¡¹å¼ç‰¹å¾
```python
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X)
```

#### äº¤å‰ç‰¹å¾
```python
# åˆ›å»ºäº¤å‰ç‰¹å¾
df['feature_cross'] = df['feature1'] * df['feature2']
```

#### æ—¶é—´ç‰¹å¾
```python
import pandas as pd

df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['day_of_week'] = df['date'].dt.dayofweek
df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
```

## ğŸ“ˆ ç‰¹å¾é€‰æ‹©

### 1. è¿‡æ»¤æ³• (Filter)

åŸºäºç»Ÿè®¡æ£€éªŒé€‰æ‹©ç‰¹å¾ï¼š

```python
from sklearn.feature_selection import SelectKBest, f_classif

selector = SelectKBest(f_classif, k=10)
X_selected = selector.fit_transform(X, y)
```

### 2. åŒ…è£…æ³• (Wrapper)

ä½¿ç”¨æ¨¡å‹æ€§èƒ½é€‰æ‹©ç‰¹å¾ï¼š

```python
from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestClassifier

selector = RFE(RandomForestClassifier(), n_features_to_select=10)
X_selected = selector.fit_transform(X, y)
```

### 3. åµŒå…¥æ³• (Embedded)

åˆ©ç”¨æ¨¡å‹è‡ªèº«çš„ç‰¹å¾é‡è¦æ€§ï¼š

```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(X, y)

# è·å–ç‰¹å¾é‡è¦æ€§
importance = model.feature_importances_
```

## ğŸ† æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

| åœºæ™¯ | å»ºè®® |
|------|------|
| çº¿æ€§æ¨¡å‹ | ç‰¹å¾æ ‡å‡†åŒ–/å½’ä¸€åŒ– |
| æ ‘æ¨¡å‹ | æ— éœ€æ ‡å‡†åŒ– |
| é«˜åŸºæ•°ç±»åˆ« | Target ç¼–ç  |
| ä½åŸºæ•°ç±»åˆ« | One-Hot ç¼–ç  |
| åæ€æ•°å€¼ | å¯¹æ•°å˜æ¢ |

### âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ•°æ®æ³„éœ²**ï¼šåªåœ¨è®­ç»ƒé›†ä¸Š fitï¼Œå† transform æµ‹è¯•é›†
2. **ç‰¹å¾è¿‡å¤š**ï¼šå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆï¼Œéœ€è¦ç‰¹å¾é€‰æ‹©
3. **ç¼ºå¤±å€¼**ï¼šæ ¹æ®ä¸šåŠ¡å«ä¹‰é€‰æ‹©å¡«å……ç­–ç•¥
4. **å¼‚å¸¸å€¼**ï¼šè€ƒè™‘æˆªæ–­æˆ–å˜æ¢å¤„ç†

## ğŸ“š å®Œæ•´ç¤ºä¾‹

```python
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer

# å®šä¹‰æ•°å€¼å’Œç±»åˆ«ç‰¹å¾
numeric_features = ['age', 'income']
categorical_features = ['gender', 'city']

# æ•°å€¼ç‰¹å¾å¤„ç†æµç¨‹
numeric_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# ç±»åˆ«ç‰¹å¾å¤„ç†æµç¨‹
categorical_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

# ç»„åˆå¤„ç†å™¨
preprocessor = ColumnTransformer([
    ('num', numeric_transformer, numeric_features),
    ('cat', categorical_transformer, categorical_features)
])

# åœ¨æ¨¡å‹ Pipeline ä¸­ä½¿ç”¨
from sklearn.ensemble import RandomForestClassifier

model = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier())
])

model.fit(X_train, y_train)
```

## ğŸ“– å»¶ä¼¸é˜…è¯»

- [æœºå™¨å­¦ä¹ å…¥é—¨](/machine-learning/introduction)
- [æ¨¡å‹è¯„ä¼°](/machine-learning/model-evaluation)
- [ç›‘ç£å­¦ä¹ ](/machine-learning/supervised-learning)
