---
title: æ–‡æœ¬åˆ†ç±»
icon: tags
---

# æ–‡æœ¬åˆ†ç±»

æ–‡æœ¬åˆ†ç±»æ˜¯ NLP çš„åŸºç¡€ä»»åŠ¡ï¼Œå°†æ–‡æœ¬å½’ç±»åˆ°é¢„å®šä¹‰çš„ç±»åˆ«ä¸­ã€‚

## ğŸ“Œ ä»»åŠ¡ä»‹ç»

### åº”ç”¨åœºæ™¯
- æƒ…æ„Ÿåˆ†æï¼ˆæ­£é¢/è´Ÿé¢ï¼‰
- åƒåœ¾é‚®ä»¶æ£€æµ‹
- æ–°é—»åˆ†ç±»
- æ„å›¾è¯†åˆ«

## ğŸ”§ å®ç°æ–¹æ³•

### ä½¿ç”¨ Transformers

```python
from transformers import pipeline

classifier = pipeline("text-classification")
result = classifier("I love this movie!")
# [{'label': 'POSITIVE', 'score': 0.9998}]
```

### å¾®è°ƒ BERT

```python
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments
)

tokenizer = AutoTokenizer.from_pretrained("bert-base-chinese")
model = AutoModelForSequenceClassification.from_pretrained(
    "bert-base-chinese",
    num_labels=2
)

# è®­ç»ƒ
trainer = Trainer(model=model, args=training_args, train_dataset=dataset)
trainer.train()
```

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | æè¿° |
|------|------|
| å‡†ç¡®ç‡ | æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹ |
| ç²¾ç¡®ç‡ | é¢„æµ‹æ­£ç¡®çš„æ­£ä¾‹æ¯”ä¾‹ |
| å¬å›ç‡ | æ‰¾åˆ°çš„æ­£ä¾‹æ¯”ä¾‹ |
| F1 | ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡ |

## ğŸ“š å»¶ä¼¸é˜…è¯»

- [NLP åŸºç¡€](/nlp/nlp-basics)
- [HuggingFace](/tools/huggingface)
