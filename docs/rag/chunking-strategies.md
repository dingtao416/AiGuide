---
title: æ–‡æœ¬åˆ†å—ç­–ç•¥
icon: scissors
---

# æ–‡æœ¬åˆ†å—ç­–ç•¥

æ–‡æœ¬åˆ†å—ï¼ˆChunkingï¼‰æ˜¯ RAG ç³»ç»Ÿä¸­å°†é•¿æ–‡æ¡£åˆ‡åˆ†ä¸ºå°ç‰‡æ®µçš„å…³é”®æ­¥éª¤ã€‚

## ğŸ“Œ ä¸ºä»€ä¹ˆéœ€è¦åˆ†å—

1. **æ¨¡å‹é™åˆ¶**ï¼šEmbedding æ¨¡å‹å’Œ LLM æœ‰ Token é•¿åº¦é™åˆ¶
2. **æ£€ç´¢ç²¾åº¦**ï¼šè¾ƒå°çš„å—æ›´å®¹æ˜“ç²¾ç¡®åŒ¹é…æŸ¥è¯¢
3. **ä¸Šä¸‹æ–‡ç›¸å…³æ€§**ï¼šåˆç†çš„å—ä¿æŒè¯­ä¹‰å®Œæ•´æ€§

## ğŸ”§ åˆ†å—æ–¹æ³•

### 1. å›ºå®šå¤§å°åˆ†å—

æœ€ç®€å•çš„æ–¹æ³•ï¼ŒæŒ‰å›ºå®šå­—ç¬¦/Token æ•°åˆ‡åˆ†ã€‚

```python
from langchain.text_splitter import CharacterTextSplitter

splitter = CharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separator="\n"
)

chunks = splitter.split_text(document)
```

**ä¼˜ç‚¹**ï¼šç®€å•ã€å¿«é€Ÿ
**ç¼ºç‚¹**ï¼šå¯èƒ½åˆ‡æ–­å¥å­æˆ–æ®µè½

### 2. é€’å½’å­—ç¬¦åˆ†å—

æŒ‰å±‚çº§åˆ†éš”ç¬¦é€’å½’åˆ‡åˆ†ï¼Œå°½é‡ä¿æŒè¯­ä¹‰å®Œæ•´ã€‚

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", "ã€‚", ".", " ", ""]
)

chunks = splitter.split_text(document)
```

**åˆ†å‰²é¡ºåº**ï¼š
1. å…ˆæŒ‰æ®µè½ `\n\n`
2. å†æŒ‰è¡Œ `\n`
3. å†æŒ‰å¥å­ `ã€‚` `.`
4. æœ€åæŒ‰å­—ç¬¦

### 3. è¯­ä¹‰åˆ†å—

åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦è¿›è¡Œåˆ†å—ã€‚

```python
from langchain_experimental.text_splitter import SemanticChunker
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
splitter = SemanticChunker(
    embeddings,
    breakpoint_threshold_type="percentile"
)

chunks = splitter.split_text(document)
```

**ä¼˜ç‚¹**ï¼šè¯­ä¹‰å®Œæ•´æ€§å¥½
**ç¼ºç‚¹**ï¼šéœ€è¦è°ƒç”¨ Embeddingï¼Œé€Ÿåº¦æ…¢

### 4. åŸºäºæ–‡æ¡£ç»“æ„

æ ¹æ®æ–‡æ¡£ç»“æ„ï¼ˆæ ‡é¢˜ã€ç« èŠ‚ï¼‰åˆ†å—ã€‚

#### Markdown åˆ†å—

```python
from langchain.text_splitter import MarkdownHeaderTextSplitter

headers = [
    ("#", "Header 1"),
    ("##", "Header 2"),
    ("###", "Header 3"),
]

splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers)
chunks = splitter.split_text(markdown_doc)
```

#### HTML åˆ†å—

```python
from langchain.text_splitter import HTMLHeaderTextSplitter

headers = [
    ("h1", "Header 1"),
    ("h2", "Header 2"),
]

splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers)
chunks = splitter.split_text(html_doc)
```

### 5. ä»£ç åˆ†å—

æ ¹æ®ä»£ç è¯­æ³•ç»“æ„åˆ†å—ã€‚

```python
from langchain.text_splitter import (
    Language,
    RecursiveCharacterTextSplitter
)

splitter = RecursiveCharacterTextSplitter.from_language(
    language=Language.PYTHON,
    chunk_size=1000,
    chunk_overlap=100
)

chunks = splitter.split_text(code)
```

## ğŸ“Š å‚æ•°è°ƒä¼˜

### Chunk Size

| åœºæ™¯ | å»ºè®®å¤§å° |
|------|----------|
| é—®ç­”ç³»ç»Ÿ | 500-1000 tokens |
| æ‘˜è¦ä»»åŠ¡ | 1000-2000 tokens |
| ä»£ç æ£€ç´¢ | å‡½æ•°/ç±»çº§åˆ« |
| å¯¹è¯ç³»ç»Ÿ | 200-500 tokens |

### Chunk Overlap

é€šå¸¸è®¾ç½®ä¸º chunk_size çš„ 10-20%ã€‚

**ä½œç”¨**ï¼š
- ä¿æŒä¸Šä¸‹æ–‡è¿ç»­æ€§
- é¿å…ä¿¡æ¯åœ¨è¾¹ç•Œä¸¢å¤±

```
Chunk 1: [       æ–‡æœ¬å†…å®¹       ]
Chunk 2:              [       æ–‡æœ¬å†…å®¹       ]
                      â†‘
                   é‡å éƒ¨åˆ†
```

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ä¿æŒè¯­ä¹‰å®Œæ•´

```python
# âŒ ä¸å¥½çš„åˆ†å— - å¥å­è¢«åˆ‡æ–­
"äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†" | "æ”¯ï¼Œå®ƒè®©æœºå™¨èƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»æ™ºèƒ½ã€‚"

# âœ… å¥½çš„åˆ†å— - å®Œæ•´å¥å­
"äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè®©æœºå™¨èƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»æ™ºèƒ½ã€‚"
```

### 2. æ·»åŠ å…ƒæ•°æ®

```python
from langchain.schema import Document

chunks_with_metadata = []
for i, chunk in enumerate(chunks):
    doc = Document(
        page_content=chunk,
        metadata={
            "source": "document.pdf",
            "chunk_index": i,
            "section": "Introduction"
        }
    )
    chunks_with_metadata.append(doc)
```

### 3. çˆ¶å­æ–‡æ¡£ç­–ç•¥

å­˜å‚¨å°å—ç”¨äºæ£€ç´¢ï¼Œå…³è”å¤§å—ç”¨äºç”Ÿæˆã€‚

```python
from langchain.retrievers import ParentDocumentRetriever
from langchain.storage import InMemoryStore

# å­å—ç”¨äºæ£€ç´¢ï¼ˆæ›´ç²¾ç¡®ï¼‰
child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)

# çˆ¶å—ç”¨äºå›ç­”ï¼ˆæ›´å®Œæ•´ï¼‰
parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)

retriever = ParentDocumentRetriever(
    vectorstore=vectorstore,
    docstore=InMemoryStore(),
    child_splitter=child_splitter,
    parent_splitter=parent_splitter
)
```

## ğŸ“ˆ è¯„ä¼°åˆ†å—è´¨é‡

### æ£€æŸ¥ç‚¹

1. **å®Œæ•´æ€§**ï¼šå—æ˜¯å¦åŒ…å«å®Œæ•´çš„æ¦‚å¿µ
2. **ç‹¬ç«‹æ€§**ï¼šå—æ˜¯å¦å¯ä»¥ç‹¬ç«‹ç†è§£
3. **ç›¸å…³æ€§**ï¼šå—æ˜¯å¦ä¸æŸ¥è¯¢ç›¸å…³
4. **å¤§å°ä¸€è‡´æ€§**ï¼šå—å¤§å°åˆ†å¸ƒæ˜¯å¦åˆç†

### è¯„ä¼°ä»£ç 

```python
def evaluate_chunks(chunks):
    sizes = [len(c) for c in chunks]
    print(f"å—æ•°é‡: {len(chunks)}")
    print(f"å¹³å‡å¤§å°: {sum(sizes)/len(sizes):.0f}")
    print(f"æœ€å°/æœ€å¤§: {min(sizes)}/{max(sizes)}")
    
    # æ£€æŸ¥è¿‡å°çš„å—
    small_chunks = [c for c in chunks if len(c) < 100]
    print(f"è¿‡å°çš„å— (<100): {len(small_chunks)}")
```

## ğŸ“š å»¶ä¼¸é˜…è¯»

- [ä»€ä¹ˆæ˜¯ RAG](/rag/what-is-rag)
- [å‘é‡æ•°æ®åº“](/rag/vector-database)
- [æ£€ç´¢ç­–ç•¥](/rag/retrieval-strategies)
